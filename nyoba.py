# -*- coding: utf-8 -*-
"""predModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N4U0DEW_0_NDQBNJ3opKh5Y-Vd-sohWD
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
url = 'https://github.com/kevynalifian/ML/raw/main/eks_minyakBumi1.xls'

# Baca file Excel dari URL
data = pd.read_excel(url)
df = pd.DataFrame(data)


#Menghapus nilai NULL
df.isnull().sum()

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten

# Load dataset and filter for "jepang"
df_jepang = df[df["Negara"] == "Jepang"]
data_olah = df_jepang[["Tahun", "Harga (per-ton)"]]

# Scale data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data_olah[["Harga (per-ton)"]])

# Split data into train and test sets
train_size = int(len(scaled_data) * 0.8)
train, test = scaled_data[0:train_size], scaled_data[train_size:]

train_size

# Create sequences for LSTM
seq_length = 5
def create_sequences(data_olah, seq_length):
    sequences = []
    for i in range(len(data_olah) - seq_length):
        sequence = data_olah[i:i + seq_length]
        sequences.append(sequence)
    return np.array(sequences)


train_sequences = create_sequences(train, seq_length)
test_sequences = create_sequences(test, seq_length)


# Prepare data for training and testing
train_sequences = np.array(train_sequences)
test_sequences = np.array(test_sequences)

test_sequences.shape

# Build CNN-LSTM model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation="relu", input_shape=(seq_length, 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(128, return_sequences=True))
model.add(LSTM(64))
model.add(Dense(1))
model.compile(loss="mae", optimizer="adam", metrics = ["mse"])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mse')<0.02 ):
      print("\nReached 0.04 MSE so cancelling training!")
      self.model.stop_training = True
callbacks = myCallback()

# Train the model
model.fit(train_sequences, train[seq_length:], epochs=100, batch_size=32, validation_data=(train_sequences, train[seq_length:]), callbacks = [callbacks])

#Make pickle file of our model
pickle.dump(model, open("model.pkl", "wb"))